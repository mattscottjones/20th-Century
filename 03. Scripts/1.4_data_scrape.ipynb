{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4536c0c3-4f3e-4508-8221-4c2bd99e76ac",
   "metadata": {},
   "source": [
    "# 1.4 Accessing Web Data with Data Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ccaa7e-f10e-4726-bd2f-5a11026fcf33",
   "metadata": {},
   "source": [
    "## This script contains the following:\n",
    "#### [1. Import Libraries](#import-libraries)\n",
    "#### [2. Scraping Wikipedia with BeautifulSoup](#scrape-beautifulsoup)\n",
    "#### [3. Scraping Wikipedia with Selenium](#scrape-selenium)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47946ed-0799-4f5a-952e-913e198b6490",
   "metadata": {},
   "source": [
    "### 1. Import Libraries<a class=\"anchor\" id=\"import-libraries\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd0e55df-c37b-4ee2-bdd2-ab448b447c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import logging\n",
    "import requests\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b928ca0-b92d-401e-8de4-a45213d4afe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Setup chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\") # Ensure GUI is off\n",
    "chrome_options.add_argument(\"--no-sandbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3188a8c-ba7e-4034-8564-fda316223904",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install Chrome driver manager\n",
    "from selenium import webdriver\n",
    "\n",
    "chromedriver_path = '/Library/Google/Chrome/chromedriver-mac-x64/chromedriver'\n",
    "driver = webdriver.Chrome(executable_path=chromedriver_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ad3c25-575a-4029-8908-3718037751e8",
   "metadata": {},
   "source": [
    "### 2. Scraping Wikipedia with BeautifulSoup<a class=\"anchor\" id=\"scrape-beautifulsoup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092f9fed-3021-4bce-97bb-669bb20703b0",
   "metadata": {},
   "source": [
    "Scraping all the text from the Wikipedia page \"Key events of the 20th century\". Not yet looking for individual elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4087fd66-8300-408e-9023-e18071259df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c900be55-a762-49cd-a471-cef32ec3473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the proper URL\n",
    "page = requests.get(\"https://en.wikipedia.org/wiki/Key_events_of_the_20th_century#Historic_events_in_the_20th_century\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cbbb68d-3d11-4f18-afb3-50a29f49f30a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create soup from the HTML data\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54b36a3b-3cf5-4265-ac8c-7beeb7414780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the text from the HTML data\n",
    "text = soup.get_text()\n",
    "text = text.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c04aba6a-992a-4c4c-b7f0-d51e89e53908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write and name the text document\n",
    "import os\n",
    "\n",
    "path = os.path.join(os.path.dirname('/Users/matthewjones/Documents/CareerFoundry/Data Visualization with Python/Achievement 1/20th-Century/02. Data/'), '20th Century Events.txt')\n",
    "    \n",
    "with open(path, 'wb') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e26dcb-a792-46eb-8f6f-cb40e7c84f37",
   "metadata": {},
   "source": [
    "### 3. Scraping Wikipedia with Selenium<a class=\"anchor\" id=\"scrape-selenium\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca1c63d-fb23-4394-a22e-fb511590fb45",
   "metadata": {},
   "source": [
    "Scraping the country names from the Wikipedia page \"List of countries\". We only want a table of all country names from this website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "456cb0ed-b2ac-4a11-892a-4994073a3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the page's contents\n",
    "page_url = \"https://simple.m.wikipedia.org/wiki/List_of_countries\"\n",
    "driver.get(page_url)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69737c3b-85d5-4d25-a17d-2dcdb40e9ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a collection of the countries\n",
    "\n",
    "#driver.get(page_url)\n",
    "#country_elems = driver.find_elements(By.CSS_SELECTOR, 'section.collapsible-block')\n",
    "#driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8e5725-2c87-416d-9ca3-04d4ed7720cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:20th_century]",
   "language": "python",
   "name": "conda-env-20th_century-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
